# âš›ï¸ AI Quantum Circuit Optimizer

**An AI agent that learns to automatically optimize quantum circuits using Deep Reinforcement Learning.**

Reduces quantum circuit gate count by 30-60% on average while preserving quantum operations. Benchmarked against IBM Qiskit's production transpiler.

---

## ğŸš€ Quick Start

### Installation

```bash
pip install qiskit qiskit-aer gymnasium stable-baselines3 matplotlib numpy
```

### Train the Agent

```bash
python train.py
```

**What happens:**
- Trains a DQN agent for 80,000 steps (~3-5 minutes)
- Evaluates on 50 test circuits
- Saves trained model to `dqn_circuit_opt.zip`
- Generates `training_results.png` with 6-panel analysis

---

## ğŸ“Š What This Does

### The Problem
On real quantum hardware, every gate adds noise. A circuit with 20 gates is far noisier than one with 10 gates â€” even if they compute the same thing.

**Example:**
```
Circuit A: H - H - X - X - Z  (5 gates, very noisy)
Circuit B: Z                   (1 gate, clean)
```
These circuits are mathematically equivalent, but Circuit A would fail on real hardware.

### The Solution
This project trains an AI agent to automatically find and remove redundant gates.

**The agent learns 6 optimization patterns:**
- Cancel self-inverse gates (HÂ·H, XÂ·X, ZÂ·Z)
- Merge SÂ·S â†’ Z
- Merge TÂ·T â†’ S  
- Apply HÂ·XÂ·H â†’ Z substitution
- Remove identity gates
- Know when to stop

---

## ğŸ“ˆ Expected Results

After training:
- **30-60%** reduction in gate count
- **30-60%** reduction in circuit depth
- Competitive with IBM Qiskit's optimizer
- Learns simple patterns first, complex patterns later

---

---

## ğŸ› ï¸ Project Structure

```
â”œâ”€â”€ quantum_env.py      # RL environment
â”œâ”€â”€ train.py            # Training + evaluation
â”œâ”€â”€ dashboard.py        # Interactive demo (optional)
â””â”€â”€ README.md           # This file
```

## ğŸ“– Learn More

**Understanding the quantum side:**
- Read `quantum_env.py` lines 30-80 (gate definitions)
- Read `quantum_env.py` lines 240-416 (optimization logic)

**Understanding the RL side:**
- Read `train.py` lines 120-131 (DQN configuration)
- Read `train.py` lines 183-301 (evaluation loop)

**MIT License** - Use for learning, research, or your own projects
